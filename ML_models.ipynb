{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code for testing other machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "cwd = os.getcwd()\n",
    "with open(f'city_config.json') as f:\n",
    "        city_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_weather_data(city_dict, path, date):\n",
    "    recent_nws = pd.read_csv(f'{path}/weather_forecast/{city_dict['issue']}/{date}/recent_NWS.csv',\n",
    "                                index_col=0)\n",
    "\n",
    "    historical_om = pd.read_csv(f'{path}/weather_forecast/{city_dict['issue']}/{date}/historical_openmeteo.csv',\n",
    "                                index_col=0)\n",
    "    \n",
    "    historical_ms = pd.read_csv(f'{path}/weather_forecast/{city_dict['issue']}/{date}/historical_meteostat.csv',\n",
    "                                index_col=0)\n",
    "\n",
    "    forecast_aw = pd.read_csv(f'{path}/weather_forecast/{city_dict['issue']}/{date}/forecast_accuweather.csv',\n",
    "                                index_col=0)\n",
    "    \n",
    "    forecast_nws = pd.read_csv(f'{path}/weather_forecast/{city_dict['issue']}/{date}/forecast_NWS.csv',\n",
    "                                index_col=0)\n",
    "\n",
    "    forecast_vc = pd.read_csv(f'{path}/weather_forecast/{city_dict['issue']}/{date}/forecast_visualcrossing.csv',\n",
    "                                index_col=0)\n",
    "    \n",
    "    all_pandas = [recent_nws, historical_om, historical_ms, forecast_aw, forecast_nws, forecast_vc]\n",
    "    \n",
    "    combined_df = pd.concat(all_pandas, ignore_index=True)\n",
    "\n",
    "    combined_df['Date'] = pd.to_datetime(combined_df['Date'])\n",
    "\n",
    "    # Group by 'Date' and calculate the average temperature\n",
    "    average_temperatures = combined_df.groupby('Date')['Temp'].mean().reset_index()\n",
    "    average_temperatures['Temp'] = average_temperatures['Temp'].round(2)\n",
    "\n",
    "    # Create separate columns for year, month, and date.\n",
    "    average_temperatures['Year'] = pd.to_datetime(average_temperatures['Date']).dt.year\n",
    "    average_temperatures['Month'] = pd.to_datetime(average_temperatures['Date']).dt.month\n",
    "    average_temperatures['Day'] = pd.to_datetime(average_temperatures['Date']).dt.day\n",
    "\n",
    "    return average_temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n",
      "Epoch 10/100, Loss: 0.28192591667175293\n",
      "Epoch 20/100, Loss: 0.12199616432189941\n",
      "Epoch 30/100, Loss: 0.057367272675037384\n",
      "Epoch 40/100, Loss: 0.052057720720767975\n",
      "Epoch 50/100, Loss: 0.05319874361157417\n",
      "Epoch 60/100, Loss: 0.04972388222813606\n",
      "Epoch 70/100, Loss: 0.04845818132162094\n",
      "Epoch 80/100, Loss: 0.04791993275284767\n",
      "Epoch 90/100, Loss: 0.047172464430332184\n",
      "Epoch 100/100, Loss: 0.04657076671719551\n",
      "Test Loss: 0.043743230402469635\n",
      "Predicted temperature for 2024.03.25: 66.19944322705268\n",
      "Austin\n",
      "Epoch 10/100, Loss: 0.2079453319311142\n",
      "Epoch 20/100, Loss: 0.07625186443328857\n",
      "Epoch 30/100, Loss: 0.03475801274180412\n",
      "Epoch 40/100, Loss: 0.03683088719844818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/30nwls9j5xn5nv008g9ngw4w0000gn/T/ipykernel_96636/1576359970.py:80: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  date_to_predict = torch.tensor([today_normalized], dtype=torch.float32).unsqueeze(1)  # Add an extra dimension for batch (batch_size=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 0.035491906106472015\n",
      "Epoch 60/100, Loss: 0.032716505229473114\n",
      "Epoch 70/100, Loss: 0.03240877017378807\n",
      "Epoch 80/100, Loss: 0.03194981813430786\n",
      "Epoch 90/100, Loss: 0.031465452164411545\n",
      "Epoch 100/100, Loss: 0.0311155766248703\n",
      "Test Loss: 0.03160594403743744\n",
      "Predicted temperature for 2024.03.25: 84.39489486455918\n",
      "Chicago\n",
      "Epoch 10/100, Loss: 0.27680110931396484\n",
      "Epoch 20/100, Loss: 0.13451610505580902\n",
      "Epoch 30/100, Loss: 0.06308562308549881\n",
      "Epoch 40/100, Loss: 0.046067144721746445\n",
      "Epoch 50/100, Loss: 0.047643646597862244\n",
      "Epoch 60/100, Loss: 0.045708537101745605\n",
      "Epoch 70/100, Loss: 0.04385094344615936\n",
      "Epoch 80/100, Loss: 0.0432555228471756\n",
      "Epoch 90/100, Loss: 0.04259509593248367\n",
      "Epoch 100/100, Loss: 0.04194939509034157\n",
      "Test Loss: 0.03897223621606827\n",
      "Predicted temperature for 2024.03.25: 66.79134700775147\n",
      "Miami\n",
      "Epoch 10/100, Loss: 0.42610493302345276\n",
      "Epoch 20/100, Loss: 0.2279249131679535\n",
      "Epoch 30/100, Loss: 0.09663362056016922\n",
      "Epoch 40/100, Loss: 0.034204740077257156\n",
      "Epoch 50/100, Loss: 0.023226013407111168\n",
      "Epoch 60/100, Loss: 0.025276722386479378\n",
      "Epoch 70/100, Loss: 0.02349633164703846\n",
      "Epoch 80/100, Loss: 0.022157222032546997\n",
      "Epoch 90/100, Loss: 0.021895870566368103\n",
      "Epoch 100/100, Loss: 0.021551989018917084\n",
      "Test Loss: 0.018319597467780113\n",
      "Predicted temperature for 2024.03.25: 87.42260009169578\n"
     ]
    }
   ],
   "source": [
    "date = '2024.03.25'\n",
    "cwd = os.getcwd()\n",
    "for i in city_data.keys():\n",
    "    print(i)\n",
    "    # Load the data and preprocess\n",
    "    data = combine_weather_data(city_data[i], cwd, date)\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data['Year'] = pd.to_datetime(data['Date']).dt.year\n",
    "    data['Month'] = pd.to_datetime(data['Date']).dt.month\n",
    "    data['Day'] = pd.to_datetime(data['Date']).dt.day\n",
    "\n",
    "    # Extract features and normalize\n",
    "    X = data[['Year', 'Month', 'Day']].values\n",
    "    y = data['Temp'].values\n",
    "\n",
    "    X_max, X_min = X.max(axis=0), X.min(axis=0)\n",
    "    y_max, y_min = y.max(), y.min()\n",
    "\n",
    "    X = (X - X_min) / (X_max - X_min)\n",
    "    y = (y - y_min) / (y_max - y_min)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    # Define the RNN model\n",
    "    class SimpleRNN(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size):\n",
    "            super(SimpleRNN, self).__init__()\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out, _ = self.rnn(x)\n",
    "            out = self.fc(out[:, -1, :])  # Use the last output of the sequence\n",
    "            return out\n",
    "\n",
    "    # Define hyperparameters\n",
    "    input_size = X_train.shape[1]  # Number of features (Year, Month, Day)\n",
    "    hidden_size = 64  # Number of hidden units in the RNN\n",
    "    output_size = 1  # Output size (temperature)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = SimpleRNN(input_size, hidden_size, output_size)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X_train_tensor.unsqueeze(1))  # Add an extra dimension for batch (batch_size=1)\n",
    "        loss = criterion(outputs.squeeze(), y_train_tensor)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor.unsqueeze(1))  # Add an extra dimension for batch (batch_size=1)\n",
    "        test_loss = criterion(test_outputs.squeeze(), y_test_tensor)\n",
    "        print(f\"Test Loss: {test_loss.item()}\")\n",
    "\n",
    "    # Make prediction for today\n",
    "    today_features = (pd.to_datetime(date).year, pd.to_datetime(date).month, pd.to_datetime(date).day)\n",
    "    today_normalized = (today_features - X_min) / (X_max - X_min)\n",
    "    date_to_predict = torch.tensor([today_normalized], dtype=torch.float32).unsqueeze(1)  # Add an extra dimension for batch (batch_size=1)\n",
    "    predicted_temperature = model(date_to_predict)\n",
    "    predicted_temperature = predicted_temperature.item() * (y_max - y_min) + y_min  # Inverse normalization\n",
    "    print(f\"Predicted temperature for {date}:\", predicted_temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n",
      "Train MSE: 0.04196169228180865\n",
      "Test MSE: 0.041097906570355586\n",
      "Predicted temperature for 2024.03.25: 55.580445587898474\n",
      "Austin\n",
      "Train MSE: 0.02758916297371686\n",
      "Test MSE: 0.028831846284349563\n",
      "Predicted temperature for 2024.03.25: 75.51799105725168\n",
      "Chicago\n",
      "Train MSE: 0.037326517027466956\n",
      "Test MSE: 0.03492970089327237\n",
      "Predicted temperature for 2024.03.25: 53.67548612748775\n",
      "Miami\n",
      "Train MSE: 0.015805656527647042\n",
      "Test MSE: 0.01460955729393199\n",
      "Predicted temperature for 2024.03.25: 83.26223842295929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "date = '2024.03.25'\n",
    "cwd = os.getcwd()\n",
    "for i in city_data.keys():\n",
    "    print(i)\n",
    "    # Load the data and preprocess\n",
    "    data = combine_weather_data(city_data[i], cwd, date)\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data['Year'] = pd.to_datetime(data['Date']).dt.year\n",
    "    data['Month'] = pd.to_datetime(data['Date']).dt.month\n",
    "    data['Day'] = pd.to_datetime(data['Date']).dt.day\n",
    "\n",
    "    # Extract features and normalize\n",
    "    X = data[['Year', 'Month', 'Day']].values\n",
    "    y = data['Temp'].values\n",
    "\n",
    "    X_max, X_min = X.max(axis=0), X.min(axis=0)\n",
    "    y_max, y_min = y.max(), y.min()\n",
    "\n",
    "    X = (X - X_min) / (X_max - X_min)\n",
    "    y = (y - y_min) / (y_max - y_min)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the linear regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    train_mse = mean_squared_error(y_train, model.predict(X_train))\n",
    "    test_mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "    print(\"Train MSE:\", train_mse)\n",
    "    print(\"Test MSE:\", test_mse)\n",
    "\n",
    "    # Make prediction for today\n",
    "    today_features = (pd.to_datetime(date).year, pd.to_datetime(date).month, pd.to_datetime(date).day)\n",
    "    today_normalized = (today_features - X_min) / (X_max - X_min)\n",
    "    date_to_predict = np.array([today_normalized])  # No need to unsqueeze for linear regression\n",
    "    predicted_temperature = model.predict(date_to_predict.reshape(1, -1))\n",
    "    predicted_temperature = predicted_temperature.item() * (y_max - y_min) + y_min  # Inverse normalization\n",
    "    print(f\"Predicted temperature for {date}:\", predicted_temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n",
      "Epoch [100/500], Loss: 2943.4688\n",
      "Epoch [200/500], Loss: 1792.2217\n",
      "Epoch [300/500], Loss: 889.2105\n",
      "Epoch [400/500], Loss: 439.8386\n",
      "Epoch [500/500], Loss: 309.8476\n",
      "Test Loss: 307.2342\n",
      "Predicted temperature for 2024-03-25: 59.134761810302734\n",
      "Austin\n",
      "Epoch [100/500], Loss: 4957.5664\n",
      "Epoch [200/500], Loss: 3306.7136\n",
      "Epoch [300/500], Loss: 1809.4319\n",
      "Epoch [400/500], Loss: 827.5840\n",
      "Epoch [500/500], Loss: 382.0824\n",
      "Test Loss: 390.9588\n",
      "Predicted temperature for 2024-03-25: 68.96963500976562\n",
      "Chicago\n",
      "Epoch [100/500], Loss: 2897.9297\n",
      "Epoch [200/500], Loss: 1790.1531\n",
      "Epoch [300/500], Loss: 946.4073\n",
      "Epoch [400/500], Loss: 539.7171\n",
      "Epoch [500/500], Loss: 428.5333\n",
      "Test Loss: 419.6447\n",
      "Predicted temperature for 2024-03-25: 57.632118225097656\n",
      "Miami\n",
      "Epoch [100/500], Loss: 5415.6211\n",
      "Epoch [200/500], Loss: 3675.0730\n",
      "Epoch [300/500], Loss: 2015.3003\n",
      "Epoch [400/500], Loss: 852.1341\n",
      "Epoch [500/500], Loss: 276.4267\n",
      "Test Loss: 267.4150\n",
      "Predicted temperature for 2024-03-25: 70.50745391845703\n"
     ]
    }
   ],
   "source": [
    "date = '2024.03.25'\n",
    "cwd = os.getcwd()\n",
    "for i in city_data.keys():\n",
    "    print(i)\n",
    "    # Load the data and preprocess\n",
    "    data = combine_weather_data(city_data[i], cwd, date)\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data['Year'] = pd.to_datetime(data['Date']).dt.year\n",
    "    data['Month'] = pd.to_datetime(data['Date']).dt.month\n",
    "    data['Day'] = pd.to_datetime(data['Date']).dt.day\n",
    "\n",
    "    # Extract features and normalize\n",
    "    X = data[['Year', 'Month', 'Day']]\n",
    "    y = data['Temp'].values\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_tensor = torch.from_numpy(X.values.astype(np.float32))\n",
    "    y_tensor = torch.from_numpy(y.astype(np.float32))\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the Transformer model\n",
    "    class TransformerModel(nn.Module):\n",
    "        def __init__(self, input_size, output_size, num_layers=2, num_heads=8, hidden_dim=64):\n",
    "            super(TransformerModel, self).__init__()\n",
    "            self.embedding = nn.Linear(input_size, hidden_dim)\n",
    "            encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, batch_first=True)\n",
    "            self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "            self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.embedding(x)\n",
    "            x = x.unsqueeze(1)  # Add sequence length dimension\n",
    "            output = self.transformer_encoder(x)\n",
    "            output = self.fc(output[:, -1, :])  # Take the last time step and apply the linear layer\n",
    "            return output\n",
    "\n",
    "    # Example usage (assuming X_train, X_test, y_train, y_test are defined)\n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = 1\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 500\n",
    "\n",
    "    # Initialize the Transformer model\n",
    "    model = TransformerModel(input_size, output_size)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training the model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs.squeeze(), y_train)  # Squeeze to remove extra dimension\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test)\n",
    "        test_loss = criterion(test_outputs.squeeze(), y_test)  # Squeeze to remove extra dimension\n",
    "        print(f'Test Loss: {test_loss.item():.4f}')\n",
    "\n",
    "    # Make prediction for 2024-03-25\n",
    "    date_to_predict = torch.tensor([[2024, 3, 25]], dtype=torch.float32)\n",
    "    predicted_temperature = model(date_to_predict)\n",
    "    print(f\"Predicted temperature for 2024-03-25:\", predicted_temperature.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "#### Testing removing temperature of predicted date from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n",
      "Test MSE: 81.04347638516414\n",
      "Predicted temperature for 2024.03.25: 59.99585390331886\n",
      "Removing forecast for 2024.03.25:\n",
      "Test MSE: 76.9017216351906\n",
      "Predicted temperature for 2024.03.25: 62.282097142857175\n",
      "\n",
      "Austin\n",
      "Test MSE: 107.2199155810471\n",
      "Predicted temperature for 2024.03.25: 80.01922142135642\n",
      "Removing forecast for 2024.03.25:\n",
      "Test MSE: 100.28662064792013\n",
      "Predicted temperature for 2024.03.25: 81.14616071428573\n",
      "\n",
      "Chicago\n",
      "Test MSE: 122.01444689918206\n",
      "Predicted temperature for 2024.03.25: 48.34487808802311\n",
      "Removing forecast for 2024.03.25:\n",
      "Test MSE: 123.26796779683092\n",
      "Predicted temperature for 2024.03.25: 43.69466214285714\n",
      "\n",
      "Miami\n",
      "Test MSE: 18.281562827637753\n",
      "Predicted temperature for 2024.03.25: 83.12555977633478\n",
      "Removing forecast for 2024.03.25:\n",
      "Test MSE: 20.113501729857088\n",
      "Predicted temperature for 2024.03.25: 84.42585142857139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "date = '2024.03.25'\n",
    "cwd = os.getcwd()\n",
    "for i in city_data.keys():\n",
    "    print(i)\n",
    "    # Load the data and preprocess\n",
    "    data = combine_weather_data(city_data[i], cwd, date)\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    \n",
    "    # Extract features\n",
    "    X = data['Date'].dt.dayofyear.values.reshape(-1, 1)  # Convert date to day of the year\n",
    "    y = data['Temp'].values\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Random Forest Regressor\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    # Compute and print the Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_test, test_predictions)\n",
    "    print(\"Test MSE:\", mse)\n",
    "\n",
    "    # Make prediction for 2024-03-12\n",
    "    date_to_predict = pd.to_datetime(\"2024-03-25\").dayofyear\n",
    "    predicted_temperature = model.predict([[date_to_predict]])\n",
    "    print(f\"Predicted temperature for {date}:\", predicted_temperature[0])\n",
    "\n",
    "    print(f'Removing forecast for {date}:')\n",
    "\n",
    "    # Convert the \"Date\" column to datetime format\n",
    "    # data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data = data[data['Date'].dt.date != pd.to_datetime(date).date()] #\n",
    "\n",
    "    # Extract features\n",
    "    X = data['Date'].dt.dayofyear.values.reshape(-1, 1)  # Convert date to day of the year\n",
    "    y = data['Temp'].values\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Random Forest Regressor\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    # Compute and print the Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_test, test_predictions)\n",
    "    print(\"Test MSE:\", mse)\n",
    "\n",
    "    # Make prediction for 2024-03-12\n",
    "    date_to_predict = pd.to_datetime(date).dayofyear\n",
    "    predicted_temperature = model.predict([[date_to_predict]])\n",
    "    print(f\"Predicted temperature for {date}:\", predicted_temperature[0])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "#### Testing removing temperature of predicted date from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n",
      "Test MSE: 64.17686068833737\n",
      "Predicted temperature for 2024.03.25: 54.681554279247464\n",
      "Removing forecast for 2024.03.25:\n",
      "Test MSE: 62.850891005037006\n",
      "Predicted temperature for 2024.03.25: 54.781336393937465\n",
      "\n",
      "Austin\n",
      "Test MSE: 83.6521873215173\n",
      "Predicted temperature for 2024.03.25: 76.46293683622841\n",
      "Removing forecast for 2024.03.25:\n",
      "Test MSE: 81.76497269110828\n",
      "Predicted temperature for 2024.03.25: 76.45952152720974\n",
      "\n",
      "Chicago\n",
      "Test MSE: 91.53435675673454\n",
      "Predicted temperature for 2024.03.25: 49.69599763766677\n",
      "Removing forecast for 2024.03.25:\n",
      "Test MSE: 87.31214007044468\n",
      "Predicted temperature for 2024.03.25: 49.26409672161121\n",
      "\n",
      "Miami\n",
      "Test MSE: 15.000087075853232\n",
      "Predicted temperature for 2024.03.25: 82.99139126115224\n",
      "Removing forecast for 2024.03.25:\n",
      "Test MSE: 15.32068441631767\n",
      "Predicted temperature for 2024.03.25: 83.2665567236451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "date = '2024.03.25'\n",
    "cwd = os.getcwd()\n",
    "for i in city_data.keys():\n",
    "    print(i)\n",
    "    # Load the data and preprocess\n",
    "    data = combine_weather_data(city_data[i], cwd, date)\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    \n",
    "    # Extract features\n",
    "    X = data['Date'].dt.dayofyear.values.reshape(-1, 1)  # Convert date to day of the year\n",
    "    y = data['Temp'].values\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Random Forest Regressor\n",
    "    model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    # Compute and print the Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_test, test_predictions)\n",
    "    print(\"Test MSE:\", mse)\n",
    "\n",
    "    # Make prediction for 2024-03-12\n",
    "    date_to_predict = pd.to_datetime(\"2024-03-25\").dayofyear\n",
    "    predicted_temperature = model.predict([[date_to_predict]])\n",
    "    print(f\"Predicted temperature for {date}:\", predicted_temperature[0])\n",
    "\n",
    "    print(f'Removing forecast for {date}:')\n",
    "\n",
    "    # Convert the \"Date\" column to datetime format\n",
    "    # data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data = data[data['Date'].dt.date != pd.to_datetime(date).date()] #\n",
    "\n",
    "    # Extract features\n",
    "    X = data['Date'].dt.dayofyear.values.reshape(-1, 1)  # Convert date to day of the year\n",
    "    y = data['Temp'].values\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Random Forest Regressor\n",
    "    model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    # Compute and print the Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_test, test_predictions)\n",
    "    print(\"Test MSE:\", mse)\n",
    "\n",
    "    # Make prediction for 2024-03-12\n",
    "    date_to_predict = pd.to_datetime(date).dayofyear\n",
    "    predicted_temperature = model.predict([[date_to_predict]])\n",
    "    print(f\"Predicted temperature for {date}:\", predicted_temperature[0])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "#### Predicting on year, month, day as separate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n",
      "Gradient Boosted Test MSE: 60.09\n",
      "Predicted temperature for 2024.03.25: 54.334188709650306\n",
      "Removing forecast for 2024.03.25:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs542_test/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs542_test/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs542_test/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Test MSE: 57.84\n",
      "Predicted temperature for 2024.03.25: 54.71128010267876\n",
      "\n",
      "Austin\n",
      "Gradient Boosted Test MSE: 75.31\n",
      "Predicted temperature for 2024.03.25: 77.59234618318064\n",
      "Removing forecast for 2024.03.25:\n",
      "Gradient Boosted Test MSE: 75.82\n",
      "Predicted temperature for 2024.03.25: 78.88147161009552\n",
      "\n",
      "Chicago\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs542_test/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs542_test/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs542_test/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Test MSE: 81.68\n",
      "Predicted temperature for 2024.03.25: 55.98398281564241\n",
      "Removing forecast for 2024.03.25:\n",
      "Gradient Boosted Test MSE: 76.01\n",
      "Predicted temperature for 2024.03.25: 51.25974759280538\n",
      "\n",
      "Miami\n",
      "Gradient Boosted Test MSE: 12.57\n",
      "Predicted temperature for 2024.03.25: 81.21175775817592\n",
      "Removing forecast for 2024.03.25:\n",
      "Gradient Boosted Test MSE: 13.26\n",
      "Predicted temperature for 2024.03.25: 81.72599983795998\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs542_test/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs542_test/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "date = '2024.03.25'\n",
    "cwd = os.getcwd()\n",
    "for i in city_data.keys():\n",
    "    print(i)\n",
    "    # Load the data and preprocess\n",
    "    data = combine_weather_data(city_data[i], cwd, date)\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    \n",
    "    # Separate the date column into year, month, and day columns\n",
    "    data['Year'] = pd.to_datetime(data['Date']).dt.year\n",
    "    data['Month'] = pd.to_datetime(data['Date']).dt.month\n",
    "    data['Day'] = pd.to_datetime(data['Date']).dt.day\n",
    "\n",
    "    # Extract features and split into training and test sets.\n",
    "    X = data[['Year', 'Month', 'Day']]\n",
    "    y = data['Temp'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train Gradient Boosted Tree Regressor.\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set and compute MSE.\n",
    "    gb_test_predictions = gb_model.predict(X_test)\n",
    "    gb_mse = mean_squared_error(y_test, gb_test_predictions)\n",
    "    print(\"Gradient Boosted Test MSE:\", round(gb_mse, 2))\n",
    "\n",
    "    # Make prediction for 2024-03-12\n",
    "    dt = datetime.strptime(date, '%Y.%m.%d') \n",
    "    date_to_predict = [[dt.year, dt.month, dt.day]]\n",
    "    predicted_temperature = gb_model.predict(date_to_predict)\n",
    "    print(f\"Predicted temperature for {date}:\", predicted_temperature[0])\n",
    "\n",
    "    print(f'Removing forecast for {date}:')\n",
    "\n",
    "    # Convert the \"Date\" column to datetime format\n",
    "    # data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data = data[data['Date'].dt.date != pd.to_datetime(date).date()]\n",
    "\n",
    "    # Separate the date column into year, month, and day columns\n",
    "    data['Year'] = pd.to_datetime(data['Date']).dt.year\n",
    "    data['Month'] = pd.to_datetime(data['Date']).dt.month\n",
    "    data['Day'] = pd.to_datetime(data['Date']).dt.day\n",
    "\n",
    "    # Extract features and split into training and test sets.\n",
    "    X = data[['Year', 'Month', 'Day']]\n",
    "    y = data['Temp'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train Gradient Boosted Tree Regressor.\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set and compute MSE.\n",
    "    gb_test_predictions = gb_model.predict(X_test)\n",
    "    gb_mse = mean_squared_error(y_test, gb_test_predictions)\n",
    "    print(\"Gradient Boosted Test MSE:\", round(gb_mse, 2))\n",
    "\n",
    "    # Make prediction for 2024-03-12\n",
    "    dt = datetime.strptime(date, '%Y.%m.%d') \n",
    "    date_to_predict = [[dt.year, dt.month, dt.day]]\n",
    "    predicted_temperature = gb_model.predict(date_to_predict)\n",
    "    print(f\"Predicted temperature for {date}:\", predicted_temperature[0])\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs542",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
